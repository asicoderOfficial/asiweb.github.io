<!doctype html>
<html lang="en">
  <head>
    <!--Latex css-->
    <link rel="stylesheet" href="https://latex.now.sh/style.css">
    <!--Code highlighting-->
    <link rel="stylesheet" href="https://latex.now.sh/prism/prism.css">
    <script src="https://cdn.jsdelivr.net/npm/prismjs/prism.min.js"></script>
    <!--Misc-->
    <meta charset="UTF-8">
    <title>Asier Serrano personal webpage & blog.</title>
    <meta name="description" content="Open source, maths & more.">
    <meta name="keywords" content="open source, reinforcement learning, maths, qlearning, openai gym">
    <meta property="og:title" content="Asier Serrano">
    <meta property="og:description" content="A blog & website to explain more in depth my process of thinking and coming up with solutions that are then open sourced on GitHub. Specially focused on reinforcement learning by now.">
    <meta property="og:type" content="website">
    <!--No cache, to refresh on GitHub pages fast.-->
    <meta http-equiv='cache-control' content='no-cache'> 
    <meta http-equiv='expires' content='0'> 
    <meta http-equiv='pragma' content='no-cache'>
  </head>

  <body id="top">
    <span class="sidenote left">
      <a href="https://asicoderofficial.github.io/asiweb.github.io/">
        <img src="../../logos/logo.png" width="200" height="100">
      </a>
    </span>
    <!-- Header -->
    <header>
      <h1><span class="latex">Reinforcement learning</h1>
      <p class="author">
        What is it?<br>
      </p>
    </header>
    <div class="abstract">
      <h2>Abstract</h2>
      <p>Humans partly learn by observing, trying, failing and retrying in order to achieve their goal. That's the main idea behind reinforcement learning. In the present page, the basic setup and concepts of this type of machine learning are exposed, as well as a brief overview of methods.</p>
    </div>

    <nav role="navigation">
      <!-- Index of contents-->
      <h2>Contents</h2>
      <ol>
        <li>
          <a href="#introduction">Introduction</a>
        </li>
        <li>
          <a href="#learningenvironment">Components and workflow</a>
        </li>
        <li>
          <a href="#notation">Notation</a>
        </li>
        <li>
          <a href="#behindthescenes">Behind the scenes</a>
        </li>
        <li>
          <a href="#resources">Useful resources</a>
        </li>
      </ol>
    </nav>
    <main>
        <article>
            <div id="introduction">
                <h2>1. Introduction</h2>
                <p>Reinforcement learning is a branch of machine learning, that deals with how to learn control strategies to optimally interact with an environment from experience.</p>
                <p>This biologically inspired idea, sets an interactive framework that then proposes an optimization problem, both of which we'll inspect next.</p>
            </div>
            <div id="learningenvironment">
                <h2>2. Components and workflow</h2>
                <figure>
                    <img id="rl-diagram" src="rl-diagram.png" width="600" height="400">
                    <figcaption>
                        Figure 1.1: Reinforcement learning workflow. Source: <a href="">Towards Data Science</a>.
                    </figcaption>
                </figure>
                <p></p>
                <p>
                As seen in Figure <a href="#rl-diagram">1.1</a>, the workflow is as follows:
                <ol>
                    <li>At a given time <i>t</i>, the <i>Agent</i> is observing the <i>State</i> for that time step.</li>
                    <li>The <b>Agent</b> interacts with the <b>Environment</b> by carrying out an <b>action</b> <i>A</i> at time step <i>t</i>.</li>
                    <li>The <i>Action</i>, may or may not change the <i>Environment</i>. Depending on its consequences, the <i>Agent</i> will get a concrete reward, and the state that it can observe, will transition to the one corresponding to the next time step.</li>
                    <li>If no termination state is reached, the process continues from 1. Else, it ends.</li>
                </ol>
                </p>
                <p>
                Now that we've seen the workflow, let's define more in depth each of the components.
                </p>
                <h3>Agent</h3>
                <p>The agent is the entity that interacts with the environment. It is the one that carries out the actions, and observes the state of the environment. It is also the one that learns from the environment, and tries to optimize its actions.</p>
                <p>There may be one or more agents in the environment.</p>
                <h3>Environment</h3>
                <p>The environment is the entity that the agent interacts with. It is the one that changes its state depending on the actions of the agent, and gives rewards to the agent.</p>
                <h3>State</h3>
                <p>The state is the representation of the environment at a given time step. It is the one that the agent observes at each time step separately, and that the environment changes depending on the actions of the agent.</p>
                <p>Each state can be either:
                    <ul>
                        <li>Fully observable: The agent can observe all the information about the state.</li>
                        <li>Partially observable: The agent can only observe a subset of the information about the state.</li>
                    </ul>
                </p>
                <h3>Action</h3>
                <p>The action is the entity that the agent carries out at each time step. It is the one that changes the state of the environment, and that the environment rewards or punishes the agent for.</p>
                <h3>Reward</h3>
                <p>The reward is the entity that the environment gives to the agent at each time step. It is the one that the agent tries to maximize, and that the agent learns from.</p>
                <p>
                The reward can be either:
                    <ul>
                        <li>Immediate: The reward is given at the same time step that the action is carried out, which would be a fully supervised learning approach, except for the fact that there is no actual dataset with target labels for each sample before beginning to solve the optimization problem.</li>
                        <li>Delayed: The reward is given at a later time step. In this case, we would categorize the learning method as semi-supervised.</li>
                    </ul>
                </p>
                <p></p>
            </div>
            <div id="notation">
                <h2>3. Notation</h2>
            </div>
            <div id="behindthescenes">
                <h2>4. Behind the scenes</h2>
                <p>
                The goal of reinforcement learning is to <b>design an optimal probabilistic policy function for deciding which actions to take given a state</b>.
                </p>
            </div>
        </article>
    </main>